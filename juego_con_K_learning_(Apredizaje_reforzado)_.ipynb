{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "juego con K_learning (Apredizaje reforzado) .ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMCAnyBF/WKMyi4flc+xFk2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabtns/Proyectos-de-Machine-Learning/blob/main/juego_con_K_learning_(Apredizaje_reforzado)_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Se importan las librerias para poder realizar el juego con el modelo de aprendizaje reforzado"
      ],
      "metadata": {
        "id": "ZuZrrVdFbLME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El proyecto consiste en realizar un modelo de aprendizaje reforzado o **Reinforcement Learning** el cual \"permite a una Inteligencia Artificial planear estrategias efectivas en base a la experimentación con los datos\".\n",
        "En esta oportunidad es un juego simple donde el modelo aprendera a jugar a con una pelota. "
      ],
      "metadata": {
        "id": "avTctY7og_QU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p42zYxSF73Fp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "from time import sleep\n",
        "from IPython.display import clear_output\n",
        "from math import ceil,floor\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La **clase agente** es el cuadrado que evitara que la pelota choque contra la superficie, por ende el modelo debe \"aprender\" mediante las recompensas y penalizaciones por cada acierto u error que se cometa.\n",
        "Las politicas se iran actualizando a medida que el modelo se sigue entrenando."
      ],
      "metadata": {
        "id": "5WNFRWMNcr2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PongAgent:\n",
        "    \n",
        "    def __init__(self, game, policy=None, discount_factor = 0.1, learning_rate = 0.1, ratio_explotacion = 0.9):\n",
        "\n",
        "        # Creamos la tabla de politicas\n",
        "        if policy is not None:\n",
        "            self._q_table = policy\n",
        "        else:\n",
        "            position = list(game.positions_space.shape)\n",
        "            position.append(len(game.action_space))\n",
        "            self._q_table = np.zeros(position)\n",
        "        \n",
        "        self.discount_factor = discount_factor\n",
        "        self.learning_rate = learning_rate\n",
        "        self.ratio_explotacion = ratio_explotacion\n",
        "\n",
        "    def get_next_step(self, state, game):\n",
        "        \n",
        "        # Damos un paso aleatorio...\n",
        "        next_step = np.random.choice(list(game.action_space))\n",
        "        \n",
        "        # o tomaremos el mejor paso...\n",
        "        if np.random.uniform() <= self.ratio_explotacion:\n",
        "            # tomar el maximo\n",
        "            idx_action = np.random.choice(np.flatnonzero(\n",
        "                    self._q_table[state[0],state[1],state[2]] == self._q_table[state[0],state[1],state[2]].max()\n",
        "                ))\n",
        "            next_step = list(game.action_space)[idx_action]\n",
        "\n",
        "        return next_step\n",
        "\n",
        "    # actualizamos las politicas con las recompensas obtenidas\n",
        "    def update(self, game, old_state, action_taken, reward_action_taken, new_state, reached_end):\n",
        "        idx_action_taken =list(game.action_space).index(action_taken)\n",
        "\n",
        "        actual_q_value_options = self._q_table[old_state[0], old_state[1], old_state[2]]\n",
        "        actual_q_value = actual_q_value_options[idx_action_taken]\n",
        "\n",
        "        future_q_value_options = self._q_table[new_state[0], new_state[1], new_state[2]]\n",
        "        future_max_q_value = reward_action_taken  +  self.discount_factor*future_q_value_options.max()\n",
        "        if reached_end:\n",
        "            future_max_q_value = reward_action_taken #maximum reward\n",
        "\n",
        "        self._q_table[old_state[0], old_state[1], old_state[2], idx_action_taken] = actual_q_value + \\\n",
        "                                              self.learning_rate*(future_max_q_value -actual_q_value)\n",
        "    \n",
        "    def print_policy(self):\n",
        "        for row in np.round(self._q_table,1):\n",
        "            for column in row:\n",
        "                print('[', end='')\n",
        "                for value in column:\n",
        "                    print(str(value).zfill(5), end=' ')\n",
        "                print('] ', end='')\n",
        "            print('')\n",
        "            \n",
        "    def get_policy(self):\n",
        "        return self._q_table\n",
        "    "
      ],
      "metadata": {
        "id": "LhLUUFNd7_n5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Con la **clase PongEnvironment** se le da los movimientos en los cuales debe moverse la **entidad** y por lo tanto se le da a elegir los movimientos."
      ],
      "metadata": {
        "id": "VGGu1bhJddv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PongEnvironment:\n",
        "    \n",
        "    def __init__(self, max_life=3, height_px = 40, width_px = 50, movimiento_px = 3):\n",
        "        \n",
        "        self.action_space = ['Arriba','Abajo']\n",
        "        \n",
        "        self._step_penalization = 0\n",
        "        \n",
        "        self.state = [0,0,0]\n",
        "        \n",
        "        self.total_reward = 0\n",
        "        \n",
        "        self.dx = movimiento_px\n",
        "        self.dy = movimiento_px\n",
        "        \n",
        "        filas = ceil(height_px/movimiento_px)\n",
        "        columnas = ceil(width_px/movimiento_px)\n",
        "        \n",
        "        self.positions_space = np.array([[[0 for z in range(columnas)] \n",
        "                                                  for y in range(filas)] \n",
        "                                                     for x in range(filas)])\n",
        "\n",
        "        self.lives = max_life\n",
        "        self.max_life=max_life\n",
        "        \n",
        "        self.x = randint(int(width_px/2), width_px) \n",
        "        self.y = randint(0, height_px-10)\n",
        "        \n",
        "        self.player_alto = int(height_px/4)\n",
        "\n",
        "        self.player1 = self.player_alto  \n",
        "        # posic. inicial del player\n",
        "        \n",
        "        self.score = 0\n",
        "        \n",
        "        self.width_px = width_px\n",
        "        self.height_px = height_px\n",
        "        self.radio = 2.5\n",
        "\n",
        "    def reset(self):\n",
        "        self.total_reward = 0\n",
        "        self.state = [0,0,0]\n",
        "        self.lives = self.max_life\n",
        "        self.score = 0\n",
        "        self.x = randint(int(self.width_px/2), self.width_px) \n",
        "        self.y = randint(0, self.height_px-10)\n",
        "        return self.state\n",
        "\n",
        "    def step(self, action, animate=False):\n",
        "        self._apply_action(action, animate)\n",
        "        done = self.lives <=0 # final\n",
        "        reward = self.score\n",
        "        reward += self._step_penalization\n",
        "        self.total_reward += reward\n",
        "        return self.state, reward , done\n",
        "\n",
        "    def _apply_action(self, action, animate=False):\n",
        "        \n",
        "        if action == \"Arriba\":\n",
        "            self.player1 += abs(self.dy)\n",
        "        elif action == \"Abajo\":\n",
        "            self.player1 -= abs(self.dy)\n",
        "            \n",
        "        self.avanza_player()\n",
        "\n",
        "        self.avanza_frame()\n",
        "\n",
        "        if animate:\n",
        "            clear_output(wait=True);\n",
        "            fig = self.dibujar_frame()\n",
        "            plt.show()\n",
        "\n",
        "        self.state = (floor(self.player1/abs(self.dy))-2, floor(self.y/abs(self.dy))-2, floor(self.x/abs(self.dx))-2)\n",
        "    \n",
        "    def detectaColision(self, ball_y, player_y):\n",
        "        if (player_y+self.player_alto >= (ball_y-self.radio)) and (player_y <= (ball_y+self.radio)):\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "    \n",
        "    def avanza_player(self):\n",
        "        if self.player1 + self.player_alto >= self.height_px:\n",
        "            self.player1 = self.height_px - self.player_alto\n",
        "        elif self.player1 <= -abs(self.dy):\n",
        "            self.player1 = -abs(self.dy)\n",
        "\n",
        "    def avanza_frame(self):\n",
        "        self.x += self.dx\n",
        "        self.y += self.dy\n",
        "        if self.x <= 3 or self.x > self.width_px:\n",
        "            self.dx = -self.dx\n",
        "            if self.x <= 3:\n",
        "                ret = self.detectaColision(self.y, self.player1)\n",
        "\n",
        "                if ret:\n",
        "                    self.score = 10\n",
        "                else:\n",
        "                    self.score = -10\n",
        "                    self.lives -= 1\n",
        "                    if self.lives>0:\n",
        "                        self.x = randint(int(self.width_px/2), self.width_px)\n",
        "                        self.y = randint(0, self.height_px-10)\n",
        "                        self.dx = abs(self.dx)\n",
        "                        self.dy = abs(self.dy)\n",
        "        else:\n",
        "            self.score = 0\n",
        "\n",
        "        if self.y < 0 or self.y > self.height_px:\n",
        "            self.dy = -self.dy\n",
        "#Se realiza el radio de la bola \n",
        "    def dibujar_frame(self):\n",
        "        fig = plt.figure(figsize=(5, 4))\n",
        "        a1 = plt.gca()\n",
        "        circle = plt.Circle((self.x, self.y), self.radio, fc='slategray', ec=\"black\")\n",
        "        a1.set_ylim(-5, self.height_px+5)\n",
        "        a1.set_xlim(-5, self.width_px+5)\n",
        "#Se realiza el rectangulo que sera la \"entidad\"\n",
        "        rectangle = plt.Rectangle((-5, self.player1), 5, self.player_alto, fc='gold', ec=\"none\")\n",
        "        a1.add_patch(circle);\n",
        "        a1.add_patch(rectangle)\n",
        "        #a1.set_yticklabels([]);a1.set_xticklabels([]);\n",
        "        plt.text(4, self.height_px, \"SCORE:\"+str(self.total_reward)+\"  LIFE:\"+str(self.lives), fontsize=12)\n",
        "        if self.lives <=0:\n",
        "            plt.text(10, self.height_px-14, \"GAME OVER\", fontsize=16)\n",
        "        elif self.total_reward >= 1000:\n",
        "            plt.text(10, self.height_px-14, \"YOU WIN!\", fontsize=16)\n",
        "        return fig"
      ],
      "metadata": {
        "id": "yW_O1jJP8GOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Por ultimo se hace la clase **juego**, donde comienza la partida y el apredizaje del modelo con sus respectivos parametros."
      ],
      "metadata": {
        "id": "PH7DyOszeX1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def play(rounds=5000, max_life=3, discount_factor = 0.1, learning_rate = 0.1,\n",
        "         ratio_explotacion=0.9,learner=None, game=None, animate=False):\n",
        "\n",
        "    if game is None:\n",
        "        # si usamos movimiento_px = 5 creamos una tabla de politicas de 8x10\n",
        "        # si usamos movimiento_px = 3 la tabla sera de 14x17\n",
        "        game = PongEnvironment(max_life=max_life, movimiento_px = 3)\n",
        "        \n",
        "    if learner is None:\n",
        "        print(\"Begin new Train!\")\n",
        "        learner = PongAgent(game, discount_factor = discount_factor,learning_rate = learning_rate, ratio_explotacion= ratio_explotacion)\n",
        "\n",
        "    max_points= -9999\n",
        "    first_max_reached = 0\n",
        "    total_rw=0\n",
        "    steps=[]\n",
        "\n",
        "    for played_games in range(0, rounds):\n",
        "        state = game.reset()\n",
        "        reward, done = None, None\n",
        "        \n",
        "        itera=0\n",
        "        while (done != True) and (itera < 3000 and game.total_reward<=1000):\n",
        "            old_state = np.array(state)\n",
        "            next_action = learner.get_next_step(state, game)\n",
        "            state, reward, done = game.step(next_action, animate=animate)\n",
        "            if rounds > 1:\n",
        "                learner.update(game, old_state, next_action, reward, state, done)\n",
        "            itera+=1\n",
        "        \n",
        "        steps.append(itera)\n",
        "        \n",
        "        total_rw+=game.total_reward\n",
        "        if game.total_reward > max_points:\n",
        "            max_points=game.total_reward\n",
        "            first_max_reached = played_games\n",
        "        \n",
        "        if played_games %500==0 and played_games >1 and not animate:\n",
        "            print(\"-- Partidas[\", played_games, \"] Avg.Puntos[\", int(total_rw/played_games),\"]  AVG Steps[\", int(np.array(steps).mean()), \"] Max Score[\", max_points,\"]\")\n",
        "                \n",
        "    if played_games>1:\n",
        "        print('Partidas[',played_games,'] Avg.Puntos[',int(total_rw/played_games),'] Max score[', max_points,'] en partida[',first_max_reached,']')\n",
        "        \n",
        "    #learner.print_policy()\n",
        "    \n",
        "    return learner, game\n",
        "\n"
      ],
      "metadata": {
        "id": "2C4uGAP18K15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iHdt__qLgDCt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquì se inicia la partida el cual tomara al modelo tiempo para poder realizar la tarea, estas \"partidas\" se ejecutàn por el tiempo necesario (alrededor de 2 min. aprox) para luego terminar el juego. \n",
        "Mediante la consola se mostrara el avance del juego. Se delimito a 5000 partidas para poder observar el comportamiento del modelo. "
      ],
      "metadata": {
        "id": "4smSASUtgMcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learner, game = play(rounds=5000, discount_factor = 0.2, learning_rate = 0.1, ratio_explotacion=0.85)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ex8lQb4w8W5G",
        "outputId": "25dbf04c-1189-4eb6-f33a-cb764bb3dcb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Begin new Train!\n",
            "-- Partidas[ 500 ] Avg.Puntos[ 10 ]  AVG Steps[ 209 ] Max Score[ 150 ]\n",
            "-- Partidas[ 1000 ] Avg.Puntos[ 17 ]  AVG Steps[ 231 ] Max Score[ 200 ]\n",
            "-- Partidas[ 1500 ] Avg.Puntos[ 21 ]  AVG Steps[ 244 ] Max Score[ 200 ]\n",
            "-- Partidas[ 2000 ] Avg.Puntos[ 27 ]  AVG Steps[ 264 ] Max Score[ 370 ]\n",
            "-- Partidas[ 2500 ] Avg.Puntos[ 31 ]  AVG Steps[ 277 ] Max Score[ 460 ]\n",
            "-- Partidas[ 3000 ] Avg.Puntos[ 35 ]  AVG Steps[ 292 ] Max Score[ 500 ]\n",
            "-- Partidas[ 3500 ] Avg.Puntos[ 39 ]  AVG Steps[ 304 ] Max Score[ 500 ]\n",
            "-- Partidas[ 4000 ] Avg.Puntos[ 40 ]  AVG Steps[ 308 ] Max Score[ 500 ]\n",
            "-- Partidas[ 4500 ] Avg.Puntos[ 41 ]  AVG Steps[ 312 ] Max Score[ 500 ]\n",
            "Partidas[ 4999 ] Avg.Puntos[ 43 ] Max score[ 500 ] en partida[ 2919 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##El proceso es sencillo y invoca a la libreria matplotlib para poder visualizar el desarrollo del juego, el algoritmo intentara **aprender** a detener la bola y se ira incrementando el \"score\" o como las recompensas por cada vez que sus \"decisiones\" sean positivas, en caso contrario las vidas que tenga por cada error se iran decrementando hasta el final del juego."
      ],
      "metadata": {
        "id": "nEIHG7Kse8HF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learner2 = PongAgent(game, policy=learner.get_policy())\n",
        "learner2.ratio_explotacion = 1.0  # con esto quitamos las elecciones aleatorias al jugar\n",
        "player = play(rounds=1, learner=learner2, game=game, animate=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "5DC_oh_r8dgp",
        "outputId": "01727997-586b-4901-ff58-a8e69d97b05f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}