{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPmfIT8m+ylZkeWcRgInGiU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabtns/Proyectos-de-Machine-Learning/blob/main/Detectores_de_manos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se busca realizar la detecciones de manos. Para ello se invoca a la libreria cv2 y mediapipe.\n",
        "Para realizar esto hace una clase y las funciones correspondientes para realizar la deteccion.\n",
        "\n",
        "\n",
        "***Realizado por Gabriel Alegre, 01/07/2023***"
      ],
      "metadata": {
        "id": "vlcGZQRvIoqP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwIpFOclIits"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "from collections import namedtuple\n",
        "\n",
        "class handDetector:\n",
        "    def __init__(self,mode=False,max_num_hands=2,min_detection=0.2,min_tracking=0.2):\n",
        "      '''Al buscar mpHands.Hands() podemos ver una serie de parametros los cuales\n",
        "      son los mismo que se usan en esta clase, solo que se ajustan a lo requerido.  '''\n",
        "        self.mode = mode\n",
        "        self.max_num_hands = max_num_hands\n",
        "        self.min_detection = min_detection\n",
        "        self.min_tracking = min_tracking\n",
        "        self.mpHands = mp.solutions.hands\n",
        "        self.hands = self.mpHands.Hands()\n",
        "        self.mkDraw = mp.solutions.drawing_utils\n",
        "\n",
        "\n",
        "    def findHands(self,img,draw=True):\n",
        "        ''' En este metodo se obtiene un parametro que en este caso se toma la camara, el cual se hace la conversion y se procesa la misma\n",
        "        con el objeto realizado, iteramos sobre el mismo para obtener los valores que liuego podemos procesar y visualizar\n",
        "\n",
        "\n",
        "        El metodo draw_landmarks lo que hace es la union entre los puntos sobre la imagen '''\n",
        "        imgRGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "        self.result = self.hands.process(imgRGB)\n",
        "\n",
        "        if self.result.multi_hand_landmarks:\n",
        "            for detection in self.result.multi_hand_landmarks:\n",
        "                if draw:\n",
        "                    self.mkDraw.draw_landmarks(img,detection,self.mpHands.HAND_CONNECTIONS)\n",
        "\n",
        "        return img\n",
        "\n",
        "    def findPosition(self,img, handNo = 0,draw = True):\n",
        "      ''' Se crea una lista la cual contendra los valores que se obtengan de la deteccion.\n",
        "\n",
        "      Se valida que haya puntos, y se guarda los valores para la detectar la cantidad de manos\n",
        "\n",
        "      Se toma los valores de la imagen, y luego se itera para obtener el ID y los ejes x,y,z y la visibilidad, se agrega a la lista y retorna la misma '''\n",
        "        limslist= []\n",
        "        if self.result.multi_hand_landmarks:\n",
        "            myhand= self.result.multi_hand_landmarks[handNo]\n",
        "            for id,num in enumerate(myhand.landmark):\n",
        "\n",
        "                h,w,c = img.shape\n",
        "                cx,cy = int(num.x * w),int(num.y * h)\n",
        "                limslist.append([id,cx,cy])\n",
        "                if draw:\n",
        "                    cv2.circle(img,(cx,cy),7,(255,0,255),cv2.FILLED)\n",
        "        return limslist\n",
        "\n",
        "\n",
        "def main():\n",
        "  '''  Por ultimo se obtiene el objeto donde esta la imagen(que en este caso es una prueba de un video), se crea el objeto donde estara la clase handDetector()\n",
        "\n",
        "\n",
        "  Luego se realiza un bucle para leer la imagen y poder encontrar los valores de las manos que percibe el codigo, para salir de la imagen simplemente se aprieta la tecla \"q\" y sale del bucle.  '''\n",
        "    ptime = 0\n",
        "    ctime = 0\n",
        "    cap = cv2.VideoCapture(\"proyecto_seguimiento\\walking-m-p4.mp4\")\n",
        "    detector = handDetector()\n",
        "    while True:\n",
        "        res,img = cap.read()\n",
        "        img = detector.findHands(img)\n",
        "        limslist = detector.findPosition(img)\n",
        "        ''' En esta lista se visualiza el punto numero 4, el cual solo se obtendran los valores de ese punto omitiendo los demas.\n",
        "        La lista retornada tiene los valores de todos los puntos de la mano que son del 1 al 20, el 4 por ejemplo es el PULGAR'''\n",
        "        if len(limslist) != 0:\n",
        "            print(limslist[4])\n",
        "\n",
        "        cv2.imshow(\"frame\",img)\n",
        "        if cv2.waitKey(1) == ord('q'):\n",
        "            break\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}